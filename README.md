# MERT Embedding Analysis for Automatic Chord Recognition

Analysis of MERT (Music Understanding Model) embeddings to evaluate their suitability for automatic chord recognition tasks. This project examines what harmonic and structural information MERT layers capture through Self-Similarity Matrix analysis and chord centroid nearest-neighbor analysis.

## ğŸ¯ Research Questions

1. **Do MERT embeddings capture chord structure?**
   - Are chord boundaries detectable in embedding space?
   - Do same-chord occurrences have similar embeddings?

2. **Which MERT layer best encodes harmonic information?**
   - Layer-by-layer comparison across all 25 transformer layers
   - Trade-offs between consistency and discrimination

3. **Does MERT organize chords according to music theory?**
   - Circle of fifths relationships
   - Relative major-minor pairs
   - Chord quality clustering (major vs minor)

4. **Can MERT succeed at chord recognition without fine-tuning?**
   - Quantitative evaluation of embedding-based chord discrimination

## ğŸ“Š Key Findings

### Self-Similarity Matrix Analysis

**Weak chord discrimination across all layers:**
- Pearson correlation with chord-label SSM: **r = 0.069** (very weak)
- F1 score for chord boundary detection: **0.296** (poor)
- All embeddings show 0.75-0.90 similarity regardless of chord (minimal separation)

**Layer comparison:**
- Layer L24: Best separation but still weak (similarity = 0.81 vs 0.93 in other layers)
- No layer shows strong chord-specific clustering
- Embeddings appear "smoothed" - capture general musical features, not fine-grained harmony

### Chord Centroid Nearest Neighbor Analysis

**Modest music theory alignment:**
- **28% of top-3 neighbors** are circle-of-fifths related (Layer L1) âœ…
- **9% of top-3 neighbors** are relative major-minor pairs (Layer L19)
- **19% same quality clustering** (majors with majors, minors with minors)

**Critical limitation:**
- Average nearest-neighbor similarity: **0.936-0.988** across all layers
- Weak discrimination: all chords appear highly similar
- Model knows relationships exist but cannot distinguish strongly

### Overall Conclusion

**MERT embeddings show limited suitability for chord recognition:**
- âœ… Captures coarse harmonic relationships (circle of fifths, relative keys)
- âŒ Cannot discriminate between chords effectively (all 0.9+ similar)
- âŒ No layer specialization for harmonic structure
- ğŸ’¡ **Task-specific fine-tuning required** for practical chord recognition

## ğŸ—ï¸ Project Structure

```
mert_analysis/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ data.yaml                  # Data paths and audio parameters
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Dataset utilities
â”‚   â”‚   â””â”€â”€ labs.py               # Chord label file parsing
â”‚   â”‚
â”‚   â”œâ”€â”€ mert/
â”‚   â”‚   â””â”€â”€ featurize.py          # MERT embedding extraction
â”‚   â”‚
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ ssm.py                # Self-similarity matrix computation
â”‚       â”œâ”€â”€ chord_aggregation.py  # Frame-to-chord aggregation
â”‚       â””â”€â”€ chord_centroids.py    # Centroid & nearest neighbor analysis
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ cache_mert_layers.py  # Extract embeddings per layer
â”‚   â”‚   â””â”€â”€ align_labels.py       # Align chord labels to frames
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ test_single_song.py           # Quick frame-level test
â”‚   â”‚   â”œâ”€â”€ test_chord_aggregation.py     # Test chord-level aggregation
â”‚   â”‚   â”œâ”€â”€ test_chord_centroids.py       # Test centroid analysis
â”‚   â”‚   â”œâ”€â”€ test_layer_comparison.py      # Compare multiple layers
â”‚   â”‚   â””â”€â”€ compute_chord_centroids.py    # Full centroid analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ export/
â”‚   â”‚   â”œâ”€â”€ export_chord_level_to_bigquery.py   # Export SSM analysis
â”‚   â”‚   â””â”€â”€ export_centroids_to_bigquery.py     # Export centroid analysis
â”‚   â”‚
â”‚   â””â”€â”€ run_chord_analysis.sh     # Main pipeline script
â”‚
â”œâ”€â”€ data/  (symlink to external drive)
â”‚   â”œâ”€â”€ raw/                      # Audio files (.mp3) and chord labels (.lab)
â”‚   â””â”€â”€ processed/                # Cached features and MERT embeddings
â”‚
â””â”€â”€ requirements.txt              # Python dependencies
```

### Data Structure

Expected data organization:
```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”œâ”€â”€ 01 - Song Title.mp3
â”‚   â”‚   â””â”€â”€ 01 Song Title.lab      # Chord annotations
â”‚   â”œâ”€â”€ 02/
â”‚   â””â”€â”€ ...
â””â”€â”€ processed/
    â”œâ”€â”€ manifest.csv                # Song metadata
    â”œâ”€â”€ {song_id}.npz              # Cached features + chord labels
    â”œâ”€â”€ {song_id}_mert.npz         # MERT embeddings (single layer)
    â””â”€â”€ mert_layers/               # Layer-wise embeddings
        â”œâ”€â”€ L0/, L1/, ..., L24/
        â””â”€â”€ Each contains {song_id}.npz
```

## ğŸ”¬ Methodology

### 1. Self-Similarity Matrix Analysis

For each song and layer:
1. Extract MERT embeddings at ~75 Hz (12,000 frames for a 3-minute song)
2. Aggregate frames to chord segments (reduce to ~100 segments)
3. Compute embedding SSM: cosine similarity between all segment pairs
4. Compute chord-label SSM: binary matrix (same chord = 1)
5. Compare SSMs using Pearson correlation and F1 score

### 2. Chord Centroid Analysis

For each song and layer:
1. Compute centroid (mean embedding) for each unique chord
2. Find k-nearest neighbors in centroid space
3. Check if neighbors align with music theory:
   - Circle of fifths: Câ†”G, Gâ†”D, Dâ†”A, etc.
   - Relative major-minor: Câ†”Am, Gâ†”Em, etc.
   - Same quality: major chords grouped together
4. Compute alignment percentages

